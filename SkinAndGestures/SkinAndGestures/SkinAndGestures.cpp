// SkinAndGestures.cpp : Defines the entry point for the console application.
// Coert van Gemeren (2017) 
// Use this code under the following terms:
// Attribution: appropriate credit + indicate if changes were made
//
// Uses: Unistroke Recognizer by Baylor Wetzel 
#include "stdafx.h"

#include <opencv2/opencv.hpp>
#include <windows.h>
#include <tchar.h> 
#include <stdio.h>
#include <strsafe.h>
#include <string>
#include <iostream>
#include "ImageProcessor.h"
#include <iostream>
using namespace std;;


using namespace DollarRecognizer;

/*
The ActiveCanvas is a struct that keeps track of the button status and gestures.

INPUT: active_templates, a list of template names which are to be recognized
 */
const int nFrames = 20;

struct ActiveCanvas
{
	// Constructor
	ActiveCanvas(const std::vector<std::string> &active_templates) :
		is_lbutton_down(false),
		is_result_shown(false),
		last_result(nullptr)
	{
		// Load the Dollar shape templates
		recognizer.loadTemplates();

		// Active the given templates
		recognizer.activateTemplates(active_templates);
	}

	// Copy of the video frame we can draw on
	cv::Mat canvas;

	// The Dollar shape recognizer
	GeometricRecognizer recognizer;

	// Unique pointer (not copyable) to the last recognition result
	std::unique_ptr<RecognitionResult> last_result;

	// Is the left mouse button pressed?
	bool is_lbutton_down;

	// Has the last recognition result been shown?
	bool is_result_shown;

	// List of recorded [x,y] coordinates
	Path2D positions;

	// number of fingers recognized in last 10 frames
	int nFingersPointer = 0;
	int nFingersPerFrame[nFrames] = { 0 };
	int nFingers;

	clock_t nRecognizedAt = clock();
	string lastCommand;
	clock_t lastResultAt = clock();
};

// Set recognized finger number in the array containing n fingers recognized in last x frames.
// Return number of fingers that was recognized most in last x frames.
void calcNFingers(ActiveCanvas* gesture_recorder, int currentNFingers) {
	int* nFingersPerFrame = gesture_recorder->nFingersPerFrame;
	int* pointer = &gesture_recorder->nFingersPointer;
	*(nFingersPerFrame + *pointer) = currentNFingers;
	*pointer = (*pointer + 1) % nFrames;

	// we have only 5 fingers so don't need more than 6 bins.
	int nfingerBins[6] = { 0 };
	for (int i = 0; i < nFrames; i++) {
		if (*(nFingersPerFrame + i) < 6 && *(nFingersPerFrame + i) >= 0) {
			// get n fingers recognized in frame 1, and increment that bin.
			nfingerBins[*(nFingersPerFrame + i)]++;
		}
	}

	// Get bin index with highest value.
	int max_value = 0;
	int max_index = 0;
	for (int i = 0; i < 6; i++) {
		if (nfingerBins[i] > max_value) {
			max_value = nfingerBins[i];
			max_index = i;
		}
	}
	if (gesture_recorder->nFingers != max_index) {
		gesture_recorder->nRecognizedAt = clock();
	}

	gesture_recorder->nFingers = max_index;
}

string checkForCommand(ActiveCanvas* gesture_recorder) {

	if ((clock() - gesture_recorder->lastResultAt) / CLOCKS_PER_SEC <= 3) {
		return gesture_recorder->lastCommand;
	}

	if (/*(clock() - gesture_recorder->nRecognizedAt) / CLOCKS_PER_SEC > 0.5
		&& */(clock() - gesture_recorder->lastResultAt) / CLOCKS_PER_SEC > 3)
	{
		string command ="";
		string fileName = "";

		if (gesture_recorder->nFingers == 3) {
			command = "water";
			fileName = "commands\\water.txt";
		}
		else if (gesture_recorder->nFingers >= 4) {
			command = "read sensors";
			fileName = "commands\\readSensors.txt";
		}
		
		ofstream myfile;
		if (fileName != "") {
			myfile.open(fileName, ios::app);
			if (myfile.is_open()) {
				CVLog(INFO) << command;
				myfile << command << ". Command executed at: " << clock();
			}
			else { CVLog(INFO) << "Unable to open file"; }
			myfile.close();

			gesture_recorder->lastCommand = command;
			gesture_recorder->lastResultAt = clock();
		}
	}
	return "No command given.";
}

void setWindow(colorEncodingVariables * encoding)
{
	cv::namedWindow("trackbars", CV_WINDOW_FREERATIO);

	cv::createTrackbar("threshold", "trackbars", &(encoding->threshold), 100);
	cv::createTrackbar("Blue weight", "trackbars", &(encoding->blue), 200);
	cv::createTrackbar("Red weight", "trackbars", &(encoding->red), 200);
	cv::createTrackbar("Y min", "trackbars", &(encoding->minY), 256);
	cv::createTrackbar("Y max", "trackbars", &(encoding->maxY), 256);

}

// Global variables
cv::Mat frame; //current frame
cv::Mat fgmask; //fg mask fg mask generated by MOG2 method
cv::BackgroundSubtractorMOG2* pMOG2; //MOG2 Background subtractor

string ExePath() {
#ifdef _WIN32
	// We're on a windows machine.
	char buffer[MAX_PATH];
	GetModuleFileNameA(NULL, buffer, MAX_PATH);
	string::size_type pos = string(buffer).find_last_of("\\/");

	string path = string(buffer).substr(0, pos);
	return path;
#else
	// We're in linux. This code is unfortunately untested, because neither of us have a linux machine.
	ssize_t count = readlink("/proc/self/exe", result, PATH_MAX);
	const char *path;
	if (count != -1) {
		path = dirname(result);
	}
	return path;
#endif
}

int main()
{
	bool useYCrCb = true; // set to false if you want to use HSV color encoding.
	int bin_size = 32;    // TODO find suitable size

	PSkinLoader pSkinLoader = PSkinLoader(bin_size, ExePath());

	colorEncodingVariables colorEncodingVars;
	setWindow(&colorEncodingVars);

	// Open the webcam
	cv::VideoCapture video_capture(0);

	// Set list of gestures to be recognized
	std::vector<std::string> active_templates = { "Triangle", "X", "Rectangle", "Circle" };
	ActiveCanvas gesture_recorder(active_templates);
	ImageProcessor processor = ImageProcessor(&(gesture_recorder.canvas));

	int key = -1;
	while (key != 27)
	{
		// Grab the webcam image
		cv::Mat capture_rgb;
		video_capture >> capture_rgb;

		cv::cvtColor(capture_rgb, gesture_recorder.canvas, cv::ColorConversionCodes::COLOR_RGB2YCrCb);

		// Initialize an empty mask
		cv::Mat test_mask = cv::Mat::zeros(gesture_recorder.canvas.size(), CV_8U);
		
		// Get probability of being skin for each pixel
		processor.getSkinProbabilities(&test_mask, &pSkinLoader, colorEncodingVars, useYCrCb);

		// Turn into a skin mask
		processor.makeMask(&test_mask);
		processor.makeBinaryImage(&test_mask);

		// Height of the canvas	
		const int canvas_height = gesture_recorder.canvas.rows;
		
		int nFingers = processor.process();

		// Get number of fingers over last n frames
		calcNFingers(&gesture_recorder, nFingers);
		nFingers = gesture_recorder.nFingers;
		// check if this is a command
		string command = checkForCommand(&gesture_recorder);

		char buff[64] = { 0 };
		sprintf(buff, "N Fingers: %d. Command: %s", nFingers, command.c_str());
		cv::putText(processor.mask_color, buff, cv::Point(8, 24), CV_FONT_NORMAL, 0.75, Color_WHITE, 1, CV_AA);

		// Place the mask color image under the original webcam image
		cv::Mat canvas;
		cv::vconcat(capture_rgb, processor.mask_color, canvas);
		
		// Show the canvas
		cv::imshow("detection result", canvas);

		// Wait for image refresh
		key = cv::waitKey(5);
	}

	return (EXIT_SUCCESS);
}